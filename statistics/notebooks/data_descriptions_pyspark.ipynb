{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mô tả dữ liệu\n",
    "- Dataset: [Dresses_Attribute_Sales](https://archive.ics.uci.edu/ml/datasets/Dresses_Attribute_Sales)\n",
    "- Associated Tasks: Classification, Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import all necessary library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot run multiple SparkContexts at once; existing SparkContext(app=PySparkShell, master=local[*]) created by <module> at /Users/hongong/virtualenv/trustingsocial/lib/python2.7/site-packages/IPython/utils/py3compat.py:289 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-39ad28e76cde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m          \u001b[0;34m.\u001b[0m\u001b[0msetMaster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"local[*]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m          .setAppName(\"Data description\"))\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mspark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.2.0/libexec/python/pyspark/context.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \"\"\"\n\u001b[1;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callsite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst_spark_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mCallSite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.2.0/libexec/python/pyspark/context.pyc\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    297\u001b[0m                         \u001b[0;34m\" created by %s at %s:%s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                         % (currentAppName, currentMaster,\n\u001b[0;32m--> 299\u001b[0;31m                             callsite.function, callsite.file, callsite.linenum))\n\u001b[0m\u001b[1;32m    300\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                     \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=PySparkShell, master=local[*]) created by <module> at /Users/hongong/virtualenv/trustingsocial/lib/python2.7/site-packages/IPython/utils/py3compat.py:289 "
     ]
    }
   ],
   "source": [
    "# initialize Spark\n",
    "conf = (SparkConf()\n",
    "         .setMaster(\"local[*]\")\n",
    "         .setAppName(\"Data description\"))\n",
    "spark = SparkContext(conf = conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reading dataset to dataframe\n",
    "schema = StructType([\n",
    "    StructField(\"Dress_ID\", StringType(), True),\n",
    "    StructField(\"Style\", StringType(), True),\n",
    "    StructField(\"Price\", StringType(), True),\n",
    "    StructField(\"Rating\", FloatType(), True),\n",
    "    StructField(\"Size\", StringType(), True),\n",
    "    StructField(\"Season\", StringType(), True),\n",
    "    StructField(\"NeckLine\", StringType(), True),\n",
    "    StructField(\"SleeveLength\", StringType(), True),\n",
    "    StructField(\"waiseline\", StringType(), True),\n",
    "    StructField(\"Material\", StringType(), True),\n",
    "    StructField(\"FabricType\", StringType(), True),\n",
    "    StructField(\"Decoration\", StringType(), True),\n",
    "    StructField(\"Pattern Type\", StringType(), True),\n",
    "    StructField(\"Recommendation\", IntegerType(), True)])\n",
    "\n",
    "df = spark.read \\\n",
    "        .schema(schema) \\\n",
    "        .format(\"com.databricks.spark.csv\") \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .load(\"Dresses_Attribute_Sales.csv\")\n",
    "\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Các loại dữ liệu\n",
    "- Nomial\n",
    "- Numbers\n",
    "- Odinal\n",
    "- Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Nomial\n",
    "df_nomial = df[[\"Style\", \"NeckLine\", \"Material\", \"Pattern Type\"]]\n",
    "df_nomial.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Numbers\n",
    "df_numbers = df[[\"Dress_ID\"]]\n",
    "df_numbers.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ordinal\n",
    "df_ordinal = df[[\"Size\"]]\n",
    "df_ordinal.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ratio\n",
    "df_ratio = df[[\"Rating\"]]\n",
    "df_ratio.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trung tâm dữ liệu\n",
    "- Trung bình (mean)\n",
    "$$\\mu = \\bar{x} = \\frac{1}{n} \\sum_{i=1}^n x_i = \\frac{1}{n} (x_1 + ... + x_n)$$\n",
    "- Trung vị (median)\n",
    "- Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_nomial.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_numbers.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ordinal.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ratio.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_rating = df_ratio.agg(F.mean(df_ratio.Rating)).first()[0]\n",
    "print \"Mean rating:\", mean_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqlContext.registerDataFrameAsTable(df_ratio, \"df_ratio\")\n",
    "\n",
    "median_rating = sqlContext.sql(\"\"\"\n",
    "    SELECT percentile(Rating, 0.5) AS median_rating \n",
    "    FROM df_ratio\n",
    "\"\"\").first()[\"median_rating\"]\n",
    "\n",
    "print \"Median rating:\", median_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts = df_ratio.groupBy(\"Rating\").count()\n",
    "\n",
    "mode_rating = counts.join(\n",
    "        counts.agg(F.max('count').alias('count')),\n",
    "        on='count'\n",
    "    ).limit(1).select(\"Rating\").first()[\"Rating\"]\n",
    "\n",
    "print \"Mode rating:\", mode_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# visualize price column\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.axvline(mean_rating, color='red', linewidth=5)\n",
    "ax.axvline(median_rating, color='green', linewidth=5)\n",
    "ax.axvline(mode_rating, color='blue', linewidth=5)\n",
    "\n",
    "# Add arrows annotating the means:\n",
    "def add_arrow(label, val, align=\"left\"):\n",
    "    ax.annotate(label + ': {:0.2f}'.format(val), xy=(val, 1), xytext=(15, 15),\n",
    "            xycoords=('data', 'axes fraction'), textcoords='offset points',\n",
    "            horizontalalignment=align, verticalalignment='center',\n",
    "            arrowprops=dict(arrowstyle='-|>', fc='black', shrinkA=0, shrinkB=0,\n",
    "                            connectionstyle='angle,angleA=0,angleB=90,rad=10'),\n",
    "            )\n",
    "\n",
    "add_arrow(\"Mean\", mean_rating)\n",
    "add_arrow(\"Median\", median_rating)\n",
    "add_arrow(\"Mode\", mode_rating)\n",
    "ax.legend(loc='upper left')\n",
    "ax.margins(0.05)\n",
    "\n",
    "bins, hist = df_ratio.select(\"Rating\").rdd.flatMap(lambda x: x).histogram(70)\n",
    "hist = np.asarray(hist)\n",
    "bins = np.asarray(bins)\n",
    "width = 0.7 * (bins[1] - bins[0])\n",
    "center = (bins[:-1] + bins[1:]) / 2\n",
    "plt.bar(center, hist, align='center', width=width)\n",
    "plt.title(\"Rating Histogram\")\n",
    "plt.xlabel(\"Rating\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biến đổi của dữ liệu \n",
    "- Khoảng đoạn (range)\n",
    "$$range = maxValue - minValue$$\n",
    "\n",
    "- Phương sai (variance)\n",
    "$$\\sigma^2 = \\frac{\\sum_{i=1}^n (x_i - \\mu)}{n}$$\n",
    "\n",
    "- Độ lệch chuẩn (standard deviation)\n",
    "$$\\sigma = \\sqrt{\\frac{\\sum_{i=1}^n (x_i - \\mu)}{n}}$$\n",
    "\n",
    "- Z-score: biến đổi từ sample mean để thực hiện Z-test\n",
    "    * Shift trung bình mẫu về 0 bằng $X - \\mu$\n",
    "    * Nén độ lệch chuẩn của mẫu ban đầu lại bằng cách chia cho $\\sigma$\n",
    "$$Z = \\frac{X - \\mu}{\\sigma}$$\n",
    "\n",
    "- Phân vị (percentile)\n",
    "$$percentile \\ of \\ x = \\frac{No. value \\ below \\ x}{n} * 100\\\\$$\n",
    "$$quartiles = \\frac{percentile * n}{100}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# range of rating\n",
    "min_rating = df_ratio.agg(F.min(df_ratio.Rating)).first()[0]\n",
    "max_rating = df_ratio.agg(F.max(df_ratio.Rating)).first()[0]\n",
    "range_rating = max_rating - min_rating\n",
    "print \"Min rating:\", min_rating\n",
    "print \"Max rating:\", max_rating\n",
    "print \"Rating range:\", range_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# variance of rating\n",
    "var_rating = df_ratio.agg(F.variance(df_ratio.Rating)).first()[0]\n",
    "print \"Rating variance:\", var_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# standard deviation of rating\n",
    "std_rating = df_ratio.agg(F.stddev(df_ratio.Rating)).first()[0]\n",
    "print \"Rating standard deviation:\", std_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# z-score of rating\n",
    "df_z_score_rating = sqlContext.sql(\"SELECT (Rating - \" + \\\n",
    "                                   str(mean_rating) + \" / \" + str(std_rating) + \\\n",
    "                                   \") as Rating FROM df_ratio\")               \n",
    "\n",
    "print \"\\nZ-score of rating:\"\n",
    "df_z_score_rating.show(5)\n",
    "\n",
    "bins, hist = df_z_score_rating.select(\"Rating\").rdd.flatMap(lambda x: x).histogram(70)\n",
    "hist = np.asarray(hist)\n",
    "bins = np.asarray(bins)\n",
    "width = 0.7 * (bins[1] - bins[0])\n",
    "center = (bins[:-1] + bins[1:]) / 2\n",
    "\n",
    "# plotting\n",
    "fig = plt.figure(figsize=(15, 5), dpi= 80, facecolor='w', edgecolor='k')\n",
    "plt.bar(center, hist, align='center', width=width)\n",
    "plt.title(\"Z score distribution\")\n",
    "plt.xlabel(\"Rating\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xác suất\n",
    "- Xác suất (probability)\n",
    "$$probability = \\frac{event(s)}{outcome(s)}$$\n",
    "\n",
    "- Phép đếm hoán vị (permutation)\n",
    "$$P(n, r) = \\frac{n!}{(n - r)!}\\\\$$\n",
    "$$n: distinct\\ object\\ to\\ choose\\ from$$\n",
    "$$r: spaces\\ to\\ fill.$$\n",
    "\n",
    "- Phép đếm tổ hợp (combination)\n",
    "$$C(n, r) = \\frac{n!}{r!(n - r)!}$$\n",
    "\n",
    "- Xác suất có điều kiện (conditional probability)\n",
    "$$P(B|A) = \\frac{P(A \\cap B)}{P(A)}$$\n",
    "\n",
    "- Biến độc lập và biến phụ thuộc (independent/dependent variable)\n",
    "    - Independent variable: \n",
    "        * Dress_ID\n",
    "        * Style\n",
    "        * Price\n",
    "        * Rating\n",
    "        * Size\n",
    "        * Season\n",
    "        * NeckLine\n",
    "        * SleeveLength\n",
    "        * waiseline\n",
    "        * Material\n",
    "        * FabricType\n",
    "        * Decoration\n",
    "        * Pattern Type\n",
    "    - Dependent variable: Recommendation\n",
    "\n",
    "- Bayes\n",
    "$$P(A|B) = \\frac{P(B|A) P(A)}{P(B)}\\\\$$\n",
    "$$Posterior = \\frac{Likelihood * Prior}{Evidence}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# probability to get rating 4.0\n",
    "# counter=Counter(df_ratio[\"Rating\"])\n",
    "# prob_of_4 = counter[4.0] * 100.0 / len(counter)\n",
    "# print \"Probability to get rating 4.0:\", prob_of_4, \"%\"\n",
    "\n",
    "bins, hist = df_z_score_rating.select(\"Rating\").rdd.flatMap(lambda x: x).histogram(70)\n",
    "hist"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
